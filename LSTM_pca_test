import pandas as pd
import keras
import numpy as np
import matplotlib.pyplot as plt
from pca import data_preparation


# Prepare the data
data_pca, data = data_preparation.prepared_data()
returns = data_pca.pop('returns')
data_close = data.pop('close')

# Function to create sequences
def create_sequences(data, target, window_size):
    X = []
    y = []
    for i in range(len(data) - window_size):
        X.append(data.iloc[i:i + window_size].values)
        y.append(target.iloc[i + window_size])
    return np.array(X), np.array(y)

# Define window size
window_size = 5

# Split the data into training, validation, and test sets
split_1 = int(len(data_pca) * 0.8)
split_2 = int(len(data_pca) * 0.9)

train_data, train_returns = data_pca[:split_1], returns[:split_1]
val_data, val_returns = data_pca[split_1:split_2], returns[split_1:split_2]
test_data, test_returns = data_pca[split_2:], returns[split_2:]

# Create sequences
X_train, y_train = create_sequences(train_data, train_returns, window_size)
X_val, y_val = create_sequences(val_data, val_returns, window_size)
X_test, y_test = create_sequences(test_data, test_returns, window_size)

print(X_train.shape, y_train.shape)
print(X_val.shape, y_val.shape)
print(X_test.shape, y_test.shape)

# Define a more sophisticated LSTM model
model2 = keras.models.Sequential()
model2.add(keras.layers.InputLayer((window_size, 4)))
model2.add(keras.layers.LSTM(128, return_sequences=True))
model2.add(keras.layers.Dropout(0.2))
model2.add(keras.layers.LSTM(64))
model2.add(keras.layers.Dropout(0.2))
model2.add(keras.layers.Dense(32, activation='relu'))
model2.add(keras.layers.Dense(1, activation='linear'))

model2.summary()

cp2 = keras.callbacks.ModelCheckpoint('model2/.keras', save_best_only=True)
model2.compile(loss=keras.losses.MeanSquaredError(), optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=[keras.metrics.RootMeanSquaredError()])

# Train the model
history = model2.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, callbacks=[cp2])

# Load the best model
model2 = keras.models.load_model('model2/.keras')

# Predictions and plotting
def plot_predictions(data, title):
    plt.plot(data['Predictions'], label='Predictions')
    plt.plot(data['Actuals'], label='Actuals')
    plt.title(title)
    plt.legend()
    plt.show()

train_predictions = model2.predict(X_train).flatten()
train_results = pd.DataFrame(data={'Predictions': train_predictions, 'Actuals': y_train.flatten()})
plot_predictions(train_results, 'Train Predictions vs Actuals')

val_predictions = model2.predict(X_val).flatten()
val_results = pd.DataFrame(data={'Predictions': val_predictions, 'Actuals': y_val.flatten()})
plot_predictions(val_results, 'Validation Predictions vs Actuals')

test_predictions = model2.predict(X_test).flatten()
test_results = pd.DataFrame(data={'Predictions': test_predictions, 'Actuals': y_test.flatten()})
plot_predictions(test_results, 'Test Predictions vs Actuals')



"""

import pandas as pd
import keras
import numpy as np
import matplotlib.pyplot as plt
from pca import data_preparation

# Prepare the data
data_pca, data = data_preparation.prepared_data()
returns = data.pop('returns')
data_close = data.pop('close')

# Function to create sequences
def create_sequences(data, target, window_size):
    X = []
    y = []
    for i in range(len(data) - window_size):
        X.append(data.iloc[i:i + window_size].values)
        y.append(target.iloc[i + window_size])
    return np.array(X), np.array(y)

# Define window size
window_size = 5

# Split the data into training, validation, and test sets
split_1 = int(len(data) * 0.8)
split_2 = int(len(data) * 0.9)

train_data, train_returns = data[:split_1], data_close[:split_1]
val_data, val_returns = data[split_1:split_2], data_close[split_1:split_2]
test_data, test_returns = data[split_2:], data_close[split_2:]

# Create sequences
X_train, y_train = create_sequences(train_data, train_returns, window_size)
X_val, y_val = create_sequences(val_data, val_returns, window_size)
X_test, y_test = create_sequences(test_data, test_returns, window_size)

print(X_train.shape, y_train.shape)
print(X_val.shape, y_val.shape)
print(X_test.shape, y_test.shape)

# Define a more sophisticated LSTM model
model2 = keras.models.Sequential()
model2.add(keras.layers.InputLayer((window_size, 9)))
model2.add(keras.layers.LSTM(128, return_sequences=True))
model2.add(keras.layers.Dropout(0.2))
model2.add(keras.layers.LSTM(64))
model2.add(keras.layers.Dropout(0.2))
model2.add(keras.layers.Dense(32, activation='relu'))
model2.add(keras.layers.Dense(1, activation='linear'))

model2.summary()

cp2 = keras.callbacks.ModelCheckpoint('model2/.keras', save_best_only=True)
model2.compile(loss=keras.losses.MeanSquaredError(), optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=[keras.metrics.RootMeanSquaredError()])

# Train the model
history = model2.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, callbacks=[cp2])

# Load the best model
model2 = keras.models.load_model('model2/.keras')

# Predictions and plotting
def plot_predictions(data, title):
    plt.plot(data['Predictions'], label='Predictions')
    plt.plot(data['Actuals'], label='Actuals')
    plt.title(title)
    plt.legend()
    plt.show()

train_predictions = model2.predict(X_train).flatten()
train_results = pd.DataFrame(data={'Predictions': train_predictions, 'Actuals': y_train.flatten()})
plot_predictions(train_results, 'Train Predictions vs Actuals')

val_predictions = model2.predict(X_val).flatten()
val_results = pd.DataFrame(data={'Predictions': val_predictions, 'Actuals': y_val.flatten()})
plot_predictions(val_results, 'Validation Predictions vs Actuals')

test_predictions = model2.predict(X_test).flatten()
test_results = pd.DataFrame(data={'Predictions': test_predictions, 'Actuals': y_test.flatten()})
plot_predictions(test_results, 'Test Predictions vs Actuals')

"""